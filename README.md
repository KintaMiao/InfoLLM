### LLM Application or Model
#### 智谱清言 ⭐️⭐️⭐️⭐️⭐️
智谱清言(GLM-4)是智谱 AI 公司于2023训练的语言模型，是目前中文大模型中数一数二的存在，其背后是`清华大学的技术支持`，因此实力强也是理所应当，目前`完全免费，无任何收费项目`
- ==Highlight==: 
	- 目前综合实力数一数二的中文大模型
	- 提供类似 GPTs 的智能体功能
	- 支持上网查询内容
- ==Official Website==:
	- 开始对话: [智谱清言](https://www.chatglm.cn/main/alltoolsdetail) **(需要登录)**
	- 官网: [智谱清言](https://chatglm.cn)
	- 开放平台: [智谱 AI 开放平台](https://open.bigmodel.cn)
- ==Relevant Models==:
	- ***GLM 系列*** **(Main)** :
		1. **GLM1**: [GitHub: GLM](https://github.com/THUDM/GLM)
		2. **GLM-130B**: [GLM-130B](https://models.aminer.cn/glm-130b/), [GitHub](https://github.com/THUDM/GLM-130B)
		3. **ChatGLM-6B**: [GitHub: ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B)
		4. **ChatGLM3**(Or ChatGLM3-6B): [GitHub:ChatGLM3](https://github.com/THUDM/ChatGLM3)
		5. **GLM4**(不开源): [智谱AI开放平台](https://open.bigmodel.cn)
	- 待更新
- ==Personal Evaluations==:
	- GLM4 成为了当前中文大模型的标杆，无论是上下文参考还是逻辑推理亦或是知识检索，GLM4 都能够轻松胜任，这使得 GLM4 成为了首选，但是其普通模式下联网检索信息的能力较差，如有联网检索信息的需求，最好切换至高级联网模式
- ==NB==: 网页端最大输入为 2000 字
#### Kimi Chat ⭐️⭐️⭐️⭐️⭐️
Kimi，由月之暗面科技有限公司(Moonshot AI)开发的人工智能助手，作为`全球首个支持 20 万中文输入`的LLM，Kimi Chat 可以说是出道即巅峰，继续深挖，其背后的技术团队更是堪称豪华阵容，同时 Moonshot 在最近也获得了 10 亿美元的融资，实力可想而知。Kimi Chat 目前也是`完全免费`
- ==Highlight==: 
	- **高保真 Context 压缩**，无可匹敌的上下文能力和超长中文输入 Tokens
	- 支持上网查询信息，且效果相当不错
- ==Official Website==:
	- 开始对话: [Kimi.ai - 帮你看更大的世界](https://kimi.moonshot.cn) **(需要登录)**
	- 官网: [Moonshot AI](https://www.moonshot.cn)
	- 开放平台: [Moonshot AI - 开放平台](https://platform.moonshot.cn/docs)
- ==Relevant Models==:
	- moonshot-v1 **(均无更多信息)**
		- moonshot-v1-8k
		- moonshot-v1-32k
		- moonshot-v1-128k
- ==Personal Evaluations==:
	- TL;DR: `印象深刻，已成为主力工具`
	- Kimi Chat让人看到了一丝曙光，其最大的优势——高保真 Context 压缩，正如白牛(huixiangdou)所言：这个亮点足够闪耀，以至于可以忽略当下缺陷。Kimi Chat对于长文本的记忆和理解能力超乎了我的想象，它不会因为文章过长而舍弃文中的一些细节，而会牢牢的记住每个字，以至于你扔给它一本小说，抽问它一些细节内容它仍然可以对答如流
	- 令我感到震惊的还有它的细节，在扔给它一篇 Markdown 文本（内含链接），你若问它这篇文章有没有什么问题，它甚至会帮你访问每个链接并告诉你这个链接有没有问题，例如我上次写错了一个链接，它就告诉我提供的链接里有一个指向了 404，那一刻我真的被它的细节所震撼
### Chinese LLM Benchmark
#### C-Eval ⭐️⭐️⭐️⭐️⭐️
包含了13948个多项选择题，涵盖了52个不同的学科和四个难度级别，结果极为科学可靠，但模型不全且只有少量模型为官方测试数据
- ==Official Website==:
	- 官网: [C-Eval: 一个适用于大语言模型的多层次多学科中文评估套件](https://cevalbenchmark.com/index_zh.html#home_zh)
	- GitHub: [ceval](https://github.com/hkust-nlp/ceval)
- ==Result==:
	- 官网: [排行榜|C-Eval：一个适用于大语言模型的多层次多学科中文评估套件](https://cevalbenchmark.com/static/leaderboard_zh.html)
	- GitHub: [ceval](https://github.com/hkust-nlp/ceval?tab=readme-ov-file#leaderboard)
#### SuperCLUE ⭐️⭐️⭐️⭐️
由4265道题目构成，其委员会包含了全球的顶尖专家，主要聚焦于大模型的四个能力象限，包括语言理解与生成、专业技能与知识、Agent智能体和安全性，进而细化为12项基础能力
- ==Official Website==:
	- 官网: [SuperCLUE：中文通用大模型综合性测评基准](https://www.clue.ai/superclue.html)
	- GitHub: [SuperCLUE](https://github.com/CLUEbenchmark/SuperCLUE)
- ==Result==:
	- 官网: 同上，左侧可选择榜单
	- Gradio(aka.SuperCLUE琅琊榜): [SuperCLUE](https://www.superclueai.com)
	- GitHub: [SuperCLUE](https://github.com/CLUEbenchmark/SuperCLUE?tab=readme-ov-file#superclue总排行榜2023年12月)
#### CLiB ⭐️⭐️⭐️
模型覆盖全面，更新相对较快，但测试题目较少，不过仍然值得参考
- ==Official Website==：缺失
- ==Result==：
	- GitHub：[chinese-llm-benchmark](https://github.com/jeinlee1991/chinese-llm-benchmark)
	- Zhihu: [CLiB中文大模型能力评测榜单（持续更新）](https://zhuanlan.zhihu.com/p/634608422)
